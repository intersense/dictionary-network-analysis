{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《文海》层次聚类hierarchical clustering\n",
    "1. NetworkX转换为图，边的方向由构字指向被解释字\n",
    "2. 获得《文海》词典的kernel：\n",
    "    不断重复：将出度为0的节点从图中删除，直到无法再继续删除\n",
    "3. Kernel定义距离 Definition Distance：即从kernel词到该词的定义路径的长度\n",
    "\n",
    "看看需要多少次，节点数量不再减少。\n",
    "\n",
    "注意：孤立点是否应该被去掉？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成《文海》字典网络\n",
    "wenhai_gephi.csv中保存了网络中所有的解释边，即从source节点到target节点\n",
    "\n",
    "以下代码将这些边和节点转换为networkx网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "with open('wenhai_gephi.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "    line = line.replace('\\n','')\n",
    "    edge = line.split(',')\n",
    "    print(edge)\n",
    "    G.add_node(edge[0])\n",
    "    G.add_node(edge[1])\n",
    "    G.add_edge(edge[1], edge[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单可视化《文海》字典网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "networkx包提供的out_degree()函数得到图中所有节点的出度，删除出度为0的节点。\n",
    "\n",
    "1. 第一次删除出度为0的节点，图中3781个节点中有1384个节点出度为0，即这些节点没有出现在任何其他节点的解释中，删掉之后图中还剩2397个节点；\n",
    "2. 继续删除剩余图中的出度为0的节点716个，图中还剩1681个节点；\n",
    "3. 继续删除剩余图中的出度为0的节点218个，图中还剩1463个节点；\n",
    "4. 继续删除剩余图中的出度为0的节点59个，图中还剩1404个节点；\n",
    "5. 继续删除剩余图中的出度为0的节点13个，图中还剩1391个节点；\n",
    "6. 继续删除剩余图中的出度为0的节点2个，图中还剩1389个节点；\n",
    "至此，网络不存在出度为0的节点，即得到《文海》的Kernel词集，供1389个西夏字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    print(n)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(G.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    #print(n)\n",
    "    #break\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    #print(n)\n",
    "    #break\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    #print(n)\n",
    "    #break\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    #print(n)\n",
    "    #break\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    #print(n)\n",
    "    #break\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degrees = G.out_degree()\n",
    "od0 = [x for x in out_degrees if x[1]==0]\n",
    "print(len(od0))\n",
    "for n in od0:\n",
    "    G.remove_node(n[0])\n",
    "print(len(G.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存《文海》字典的kernel为gephi格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"kernel.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 强连接部件SCC的检测\n",
    "\n",
    "nx.strongly_connected_components(G)\n",
    "Generate nodes in strongly connected components of graph.\n",
    "### 六个节点的scc （1）\n",
    "{'𘄅', '𘘷', '𘄄', '𘙎', '𘙥', '𗨷'}\n",
    "    1. 𘄅：子、幼子、孩童\n",
    "    2. 𘘷：孩子、小儿、男\n",
    "    3. 𘄄：男、子\n",
    "    4. 𘙎：生、产\n",
    "    5. 𘙥：安静、徐徐\n",
    "    6. 𗨷：安详、徐徐\n",
    "### 五个节点的scc （1）\n",
    "{'𗆽', '𗅶', '𗕮', '𗕰', '𗂍'}\n",
    "1. 𗆽：抽、取\n",
    "2. 𗅶：摘去、拔去\n",
    "3. 𗕮：扯、摘去、拔去\n",
    "4. 𗕰：抽、拔\n",
    "5. 𗂍：抽、拔、取\n",
    "\n",
    "### 四个节点的scc （17）\n",
    "\n",
    "{'𗹻', '𗹿', '𘅺', '𘅚'}, {'𗁜', '𗑻', '𗛩', '𗑝'}, {'𗞋', '𗩅', '𗞢', '𗚖'}, {'𘗪', '𘗫', '𘗬', '𘗯'}, {'𗵘', '𗦞', '𗍺', '𗢹'}, {'𗖥', '𘐍', '𗖂', '𘏉'}, {'𗰁', '𗹤', '𗀇', '𗦣'}, {'𗬳', '𗅉', '𗄪', '𘁘'}, {'𗍅', '𘃨', '𘃡', '𗍖'}, {'𗳚', '𗳛', '𗎻', '𗳦'}, {'𘈉', '𘔍', '𗷖', '𘈈'}, {'𗝡', '𗿉', '𘔳', '𗞦'}, {'𗲅', '𗲄', '𗇒', '𗤵'}, {'𘋜', '𗄼', '𗛏', '𗛃'},  {'𗫏', '𘜀', '𗩫', '𗕪'}, {'𘐚', '𘒾', '𘐥', '𘐋'}, {'𘓇', '𘓁', '𘏬', '𘓆'}\n",
    "1. {'𗹻', '𗹿', '𘅺', '𘅚'}\n",
    "    1. 𗹻：族姓\n",
    "    2. 𗹿：族姓\n",
    "    3. 𘅺：【代】（草名）\n",
    "    4. 𘅚：族姓，西夏人族\n",
    "2. {'𗁜', '𗑻', '𗛩', '𗑝'}\n",
    "    1. 𗁜：脊、梁\n",
    "    2. 𗑻：亲人、关节\n",
    "    3. 𗛩：梁、檩\n",
    "    4. 𗑝：节、辈\n",
    "3. {'𗞋', '𗩅', '𗞢', '𗚖'}\n",
    "    1. 𗞋：桌\n",
    "    2. 𗩅：族姓\n",
    "    3. 𗞢：盘\n",
    "    4. 𗚖：案\n",
    "4. {'𘗪', '𘗫', '𘗬', '𘗯'}\n",
    "    1. 𘗪：欺、违\n",
    "    2. 𘗫：虛、諛、諂、妄、佞、詐、謊\n",
    "    3. 𘗬：欺、騙、詐 \n",
    "    4. 𘗯：矫、诈\n",
    "5. {'𗵘', '𗦞', '𗍺', '𗢹'}\n",
    "    1. 𗵘：道、路\n",
    "    2. 𗦞：跪、拜\n",
    "    3. 𗍺：敬礼、礼拜\n",
    "    4. 𗢹：揖\n",
    "6. {'𗖥', '𘐍', '𗖂', '𘏉'}\n",
    "    1. 𗖥：劝\n",
    "    2. 𘐍：穿、贯穿\n",
    "    3. 𗖂：劝\n",
    "    4. 𘏉：穿\n",
    "7. {'𗰁', '𗹤', '𗀇', '𗦣'}\n",
    "    1. 𗰁：堪、勝、能、可\n",
    "    2. 𗹤：勝\n",
    "    3. 𗀇：強、能、勝\n",
    "    4. 𗦣：勝、能\n",
    "8. {'𗬳', '𗅉', '𗄪', '𘁘'}\n",
    "    1. 𗬳：外表、背后、防护\n",
    "    2. 𗅉：后、更、及\n",
    "    3. 𗄪：背、后、叛、畔\n",
    "    4. 𘁘：背后\n",
    "9. {'𗍅', '𘃨', '𘃡', '𗍖'}\n",
    "    1. 𗍅：工、匠\n",
    "    2. 𘃨：做、作、造作、巧\n",
    "    3. 𘃡：做、作、為、與\n",
    "    4. 𗍖：筋、劲\n",
    "10. {'𗳚', '𗳛', '𗎻', '𗳦'}\n",
    "    1. 𗳚：圮\n",
    "    2. 𗳛：族姓\n",
    "    3. 𗎻：圮\n",
    "    4. 𗳦：平、等、齊\n",
    "11. {'𘈉', '𘔍', '𗷖', '𘈈'}\n",
    "    1. 𘈉: 供；趣；赠\n",
    "    2. 𘔍: 饋贈\n",
    "    3. 𗷖: 施、贈\n",
    "    4. 𘈈：施、赐\n",
    "12. {'𗝡', '𗿉', '𘔳', '𗞦'}\n",
    "    1. 𗝡：污、染\n",
    "    2. 𗿉：烟\n",
    "    3. 𘔳：氣、焰\n",
    "    4. 𗞦：薰 \n",
    "13. {'𗲅', '𗲄', '𗇒', '𗤵'}\n",
    "    1. 𗲅：繫、縛、结\n",
    "    2. 𗲄：结\n",
    "    3. 𗇒：繩索、捆綁\n",
    "    4. 𗤵：繫結\n",
    "14. {'𘋜', '𗄼', '𗛏', '𗛃'}\n",
    "    1. 𘋜：病患\n",
    "    2. 𗄼：來、降\n",
    "    3. 𗛏：來\n",
    "    4. 𗛃：來\n",
    "15. {'𗫏', '𘜀', '𗩫', '𗕪'}\n",
    "    1. 𗫏：少、幼\n",
    "    2. 𘜀：青年、壮\n",
    "    3. 𗩫：女\n",
    "    4. 𗕪：女\n",
    "16. {'𘐚', '𘒾', '𘐥', '𘐋'} \n",
    "    1. 𘐚：澄清\n",
    "    2. 𘒾：老、皱\n",
    "    3. 𘐥：瓶、瓮、罐\n",
    "    4. 𘐋：澄、放笊篱、杓\n",
    "17. {'𘓇', '𘓁', '𘏬', '𘓆'}\n",
    "    1. 𘓇：勞累、勞苦\n",
    "    2. 𘓁：及、雖、與、并 助詞 連詞\n",
    "    3. 𘏬：秤\n",
    "    4. 𘓆：論\n",
    "    \n",
    "### 三字scc （59）\n",
    "{'𗼗', '𗍜', '𘂓'}, {'𘚾', '𘚽', '𗆭'}, {'𘓫', '𘐀', '𗿌'}, {'𗠛', '𘙴', '𗍂'}, {'𗻵', '𘟋', '𘟌'}, {'𗬆', '𗫲', '𘆠'}, {'𘌤', '𗝊', '𘇭'}, {'𗛖', '𗃼', '𗃞'}, {'𗞓', '𘂂', '𗌘'}, {'𗞉', '𗰺', '𗱂'}, {'𗫹', '𗔼', '𗔯'}, {'𘍞', '𗤩', '𘃫'}, {'𗍍', '𗼁', '𗌹'}, {'𗓁', '𘎄', '𗐴'}, {'𘍳', '𘍷', '𘍻'}, {'𘌷', '𗰛', '𘌱'}, {'𗘂', '𘋽', '𗗻'}, {'𗪬', '𗧣', '𗤼'}, {'𗦪', '𗦨', '𗆘'}, {'𗌈', '𗈠', '𗈑'}, {'𗪠', '𘀎', '𗪙'}, {'𗢭', '𗘶', '𗠅'}, {'𘈧', '𗷾', '𗖊'}, {'𘜄', '𘜃', '𘜆'}, {'𗉰', '𗉲', '𗉘'}, {'𗸆', '𘟏', '𗪺'}, {'𗹠', '𘗁', '𗹡'}, {'𗩒', '𗤕', '𗲓'}, {'𘇨', '𗴂', '𗴃'}, {'𗑗', '𗒘', '𗵒'}, {'𗷮', '𗼣', '𗷭'}, {'𗰱', '𗰵', '𗨣'}, {'𘐢', '𘐅', '𘃧'}, {'𘑘', '𘖶', '𘑗'}, {'𗢕', '𗒯', '𗈀'}, {'𗬔', '𘛸', '𗬓'}, {'𗮀', '𗄯', '𗭼'}, {'𗹏', '𘌴', '𗹘'}, {'𗈪', '𗈬', '𗥼'}, {'𘃥', '𘗸', '𘃠'}, {'𗩍', '𘓓', '𗡡'}, {'𗉣', '𗟻', '𗉭'}, {'𗅡', '𗔾', '𘍫'}, {'𗊽', '𘙩', '𘝮'}, {'𘔭', '𗣱', '𘔪'}, {'𗉥', '𗵰', '𗉬'}, {'𗰽', '𘄗', '𘌻'}, {'𘊱', '𘊰', '𘎽'}, {'𗁣', '𗁤', '𗴒'}, {'𘃆', '𗱀', '𘂬'}, {'𘏤', '𗓟', '𗥃'}, {'𗈱', '𗅂', '𘈃'}, {'𗂇', '𗁅', '𗉢'}, {'𗢉', '𗢿', '𗢈'}, {'𗢋', '𘎳', '𘄝'}, {'𗩖', '𗰬', '𗦳'}, {'𗸩', '𗸫', '𘈑'}, {'𘆽', '𘐑', '𘆝'}, {'𗁴', '𘆯', '𗃆'}\n",
    "1. '𗼗', '𗍜', '𘂓'\n",
    "    1. 𗼗：浅\n",
    "    2. 𗍜：宽、浅\n",
    "    3. 𘂓：浅\n",
    "2. '𘚾', '𘚽', '𗆭'\n",
    "    1. 𘚾: 趨、急行、疾馳\n",
    "    2. 𘚽: 跑、馳、奔\n",
    "    3. 𗆭: 追逐\n",
    "3. '𘓫', '𘐀', '𗿌'\n",
    "    1. 𘓫: 羌、藏、巧匠\n",
    "    2. 𘐀: 羌、藏、吐藩\n",
    "    3. 𗿌：鳥名\n",
    "4. '𗠛', '𘙴', '𗍂'\n",
    "    1. 𗠛：食、吃、吞、飲\n",
    "    2. 𘙴：咽、喉\n",
    "    3. 𗍂：喉、哺\n",
    "5. '𗻵', '𘟋', '𘟌'\n",
    "    1. 𗻵：䓤、韭、蒜 \n",
    "    2. 𘟋：辣、辛、痛\n",
    "    3. 𘟌：椒 \n",
    "6. '𗬆', '𗫲', '𘆠'\n",
    "    1. 𗬆：族姓\n",
    "    2. 𗫲：族姓\n",
    "    3. 𘆠：灰白色\n",
    "7. '𘌤', '𗝊', '𘇭\n",
    "    1. 𘌤: 條 \n",
    "    2. 𗝊: 梁\n",
    "    3. 𘇭: 缚绳、城\n",
    "8. '𗛖', '𗃼', '𗃞'\n",
    "    1. 𗛖: 荆棘\n",
    "    2. 𗃼: 蛆\n",
    "    3. 𗃞: 小狗\n",
    "9. '𗞓', '𘂂', '𗌘'\n",
    "    1. 𗞓: 櫻\n",
    "    2. 𘂂: 神\n",
    "    3. 𗌘: 酪\n",
    "10. '𗞉', '𗰺', '𗱂'\n",
    "    1. 𗞉: 巧\n",
    "    2. 𗰺: 急速\n",
    "    3. 𗱂: 力\n",
    "11. '𗫹', '𗔼', '𗔯'\n",
    "    1. 𗫹：爭、打、斗\n",
    "    2. 𗔼：爭、戰\n",
    "    3. 𗔯：爭\n",
    "12. '𘍞', '𗤩', '𘃫'\n",
    "    1. 𘍞：凡；圓；院、堂\n",
    "    2. 𗤩：圆、院、族性、名\n",
    "    3. 𘃫：土坯、砖坯\n",
    "13. '𗍍', '𗼁', '𗌹'\n",
    "    1. 𗍍：兔、卯\n",
    "    2. 𗼁：兽\n",
    "    3. 𗌹：野兽\n",
    "14. '𗓁', '𘎄', '𗐴'\n",
    "    1. 𗓁：聽、聞\n",
    "    2. 𘎄：聽、聞\n",
    "    3. 𗐴：耳\n",
    "15. '𘍳', '𘍷', '𘍻'\n",
    "    1. 𘍳：特、殊\n",
    "    2. 𘍷：特、尊\n",
    "    3. 𘍻：特殊、超、迥 \n",
    "16. '𘌷', '𗰛', '𘌱'\n",
    "    1. 𘌷：渡、度、過\n",
    "    2. 𗰛：渡、過、越、超、逾\n",
    "    3. 𘌱：渡、度、往\n",
    "17. '𗘂', '𘋽', '𗗻'\n",
    "    1. 𗘂：犬、狗\n",
    "    2. 𘋽：犬、狗 \n",
    "    3. 𗗻：狗、犬、戌 \n",
    "18. '𗪬', '𗧣', '𗤼'\n",
    "    1. 𗪬：夜、晚\n",
    "    2. 𗧣：明日、夜\n",
    "    3. 𗤼：夜、冥、暗\n",
    "19. '𗦪', '𗦨', '𗆘'\n",
    "    1. 𗦪：捲、皺\n",
    "    2. 𗦨：收縮\n",
    "    3. 𗆘：縮、皺 \n",
    "20. '𗌈', '𗈠', '𗈑'\n",
    "    1. 𗌈：迷惑、愚\n",
    "    2. 𗈠：錯、過、謬、誤\n",
    "    3. 𗈑：苦罰 \n",
    "21. '𗪠', '𘀎', '𗪙'\n",
    "    1. 𗪠：晚、名、夕\n",
    "    2. 𘀎：黑暗\n",
    "    3. 𗪙：俗、愚、頑\n",
    "22. '𗢭', '𗘶', '𗠅'\n",
    "    1. 𗢭：九\n",
    "    2. 𗘶：迅雷\n",
    "    3. 𗠅：分食\n",
    "23. '𘈧', '𗷾', '𗖊'\n",
    "    1. 𘈧：传、交换、易、试\n",
    "    2. 𗷾：侍奉\n",
    "    3. 𗖊：使、使者\n",
    "24. '𘜄', '𘜃', '𘜆'\n",
    "    1. 𘜄：等、同、比\n",
    "    2. 𘜃：齊、等、同\n",
    "    3. 𘜆：克服、胜利、角力\n",
    "25. '𗉰', '𗉲', '𗉘'\n",
    "    1. 𗉰：追求、自勵\n",
    "    2. 𗉲：彼、爾 助詞\n",
    "    3. 𗉘：爾、彼、他、其、爭、寧、相 助詞 代詞\n",
    "26. '𗸆', '𘟏', '𗪺'\n",
    "27. '𗹠', '𘗁', '𗹡'}, {'𗩒', '𗤕', '𗲓'}, {'𘇨', '𗴂', '𗴃'}, {'𗑗', '𗒘', '𗵒'}, {'𗷮', '𗼣', '𗷭'}, {'𗰱', '𗰵', '𗨣'}, {'𘐢', '𘐅', '𘃧'}, {'𘑘', '𘖶', '𘑗'}, {'𗢕', '𗒯', '𗈀'}, {'𗬔', '𘛸', '𗬓'}, {'𗮀', '𗄯', '𗭼'}, {'𗹏', '𘌴', '𗹘'}, {'𗈪', '𗈬', '𗥼'}, {'𘃥', '𘗸', '𘃠'}, {'𗩍', '𘓓', '𗡡'}, {'𗉣', '𗟻', '𗉭'}, {'𗅡', '𗔾', '𘍫'}, {'𗊽', '𘙩', '𘝮'}, {'𘔭', '𗣱', '𘔪'}, {'𗉥', '𗵰', '𗉬'}, {'𗰽', '𘄗', '𘌻'}, {'𘊱', '𘊰', '𘎽'}, {'𗁣', '𗁤', '𗴒'}, {'𘃆', '𗱀', '𘂬'}, {'𘏤', '𗓟', '𗥃'}, {'𗈱', '𗅂', '𘈃'}, {'𗂇', '𗁅', '𗉢'}, {'𗢉', '𗢿', '𗢈'}, {'𗢋', '𘎳', '𘄝'}, {'𗩖', '𗰬', '𗦳'}, {'𗸩', '𗸫', '𘈑'}, {'𘆽', '𘐑', '𘆝'}, {'𗁴', '𘆯', '𗃆'}\n",
    "\n",
    "### 两个节点的scc （293）\n",
    "{'𘀏', '𘀑'}, {'𗚦', '𗚓'}, {'𗜹', '𗜦'}, {'𗔟', '𘍿'}, {'𗩇', '𗿡'}, {'𗍎', '𗍘'}, {'𗿦', '𗿽'}, {'𘓰', '𘓸'}, {'𗗑', '𗗒'}, {'𘔥', '𘔤'}, {'𗪌', '𗩀'}, {'𘛅', '𘉀'}, {'𗨜', '𗿝'}, {'𗿤', '𗿼'}, {'𗇅', '𗨬'}, {'𗬃', '𗺺'}, {'𘒂', '𗺻'}, {'𗺞', '𗠍'}, {'𗫐', '𗸒'}, {'𗋐', '𗧏'}, {'𗊀', '𗤹'}, {'𘖅', '𗥬'}, {'𗐨', '𗐩'}, {'𗛭', '𗣔'}, {'𘜲', '𘞐'}, {'𗛟', '𗵃'}, {'𗊄', '𗚹'}, {'𘀐', '𗞌'}, {'𗅾', '𗝗'}, {'𗝨', '𘌸'}, {'𘌧', '𗁋'}, {'𘑦', '𘑧'}, {'𗂆', '𗓙'}, {'𗬊', '𗬋'}, {'𗟥', '𘆌'}, {'𗁕', '𗁿'}, {'𗟨', '𗳫'}, {'𗳘', '𘓯'}, {'𘀗', '𘓺'}, {'𗟎', '𘝋'}, {'𗝰', '𗯽'}, {'𘙟', '𗒸'}, {'𗺴', '𗝙'}, {'𗛯', '𗛸'}, {'𗛥', '𗍶'}, {'𗝠', '𗪏'}, {'𘃻', '𗦆'}, {'𘒛', '𗫒'}, {'𗦺', '𗙖'}, {'𗕻', '𗢇'}, {'𘋾', '𘋺'}, {'𗗱', '𗗽'}, {'𗩌', '𘈦'}, {'𘎭', '𘚟'}, {'𘑸', '𘑫'}, {'𗇞', '𘗼'}, {'𘛌', '𗽓'}, {'𗐹', '𗑹'}, {'𗼯', '𗽃'}, {'𗶲', '𗷌'}, {'𗉁', '𘓻'}, {'𗜐', '𘍽'}, {'𗱕', '𗯨'}, {'𗕾', '𗖺'}, {'𗶈', '𗶆'}, {'𗈵', '𗈸'}, {'𗘢', '𗘡'}, {'𗾄', '𗯴'}, {'𗼺', '𘏎'}, {'𗓳', '𘆲'}, {'𗒈', '𘌩'}, {'𘛛', '𘄦'}, {'𗳩', '𗳝'}, {'𘉆', '𘉅'}, {'𗩯', '𗮔'}, {'𗆪', '𗅃'}, {'𗕭', '𗕲'}, {'𗕝', '𗴊'}, {'𗅄', '𗱪'}, {'𘑄', '𘏥'}, {'𗩚', '𗪚'}, {'𘇢', '𘇡'}, {'𘊵', '𘊴'}, {'𗍽', '𘐔'}, {'𗟼', '𘒧'}, {'𗔜', '𗑦'}, {'𘘀', '𘗾'}, {'𗗠', '𘎻'}, {'𘀼', '𗖸'}, {'𘞝', '𗠯'}, {'𘉥', '𘉨'}, {'𗠀', '𘐙'}, {'𗗬', '𗴉'}, {'𗖶', '𗤄'}, {'𗖞', '𘒥'}, {'𘄩', '𘄨'}, {'𗰳', '𗰯'}, {'𘄞', '𗰎'}, {'𗙂', '𗭹'}, {'𗰇', '𗰆'}, {'𘗎', '𘔃'}, {'𘘄', '𘖷'}, {'𗄒', '𗄈'}, {'𘃤', '𗭍'}, {'𘃝', '𘟬'}, {'𗂌', '𗃎'}, {'𗯤', '𗯢'}, {'𘙓', '𘙀'}, {'𘘃', '𗉩'}, {'𘂫', '𘂿'}, {'𘘓', '𘃸'}, {'𗢃', '𗯿'}, {'𘛜', '𘛍'}, {'𘂣', '𗃃'}, {'𘀞', '𗋺'}, {'𗋼', '𘎴'}, {'𗮸', '𗌊'}, {'𗊹', '𘄯'}, {'𗊢', '𗱶'}, {'𘂺', '𗌎'}, {'𘘴', '𘏕'}, {'𘞌', '𗋭'}, {'𘘎', '𘍄'}, {'𗃒', '𗱼'}, {'𗋻', '𘜹'}, {'𗫋', '𘝪'}, {'𗅝', '𗕣'}, {'𗏡', '𗐃'}, {'𗅑', '𗎏'}, {'𗼕', '𗟶'}, {'𘑅', '𗱿'}, {'𘐿', '𘏐'}, {'𘀀', '𘀁'}, {'𘘯', '𗈞'}, {'𘆋', '𘐊'}, {'𘆒', '𘆏'}, {'𗇵', '𗫿'}, {'𗜬', '𗜮'}, {'𘍔', '𘍒'}, {'𗒴', '𗔢'}, {'𗂢', '𗁶'}, {'𗨵', '𗥜'}, {'𗸦', '𗣕'}, {'𗦊', '𗣿'}, {'𗼦', '𗵞'}, {'𘉡', '𘉟'}, {'𘉐', '𗵺'}, {'𘎆', '𗱠'}, {'𗫔', '𘟣'}, {'𘛥', '𘛤'}, {'𗛮', '𗣖'}, {'𘋃', '𘋁'}, {'𗐲', '𗑫'}, {'𗣪', '𗧈'}, {'𗠽', '𗴢'}, {'𘘞', '𗟸'}, {'𗻑', '𗂩'}, {'𗁢', '𗘫'}, {'𗵚', '𗅠'}, {'𘒗', '𗅷'}, {'𘒑', '𗵎'}, {'𗉫', '𘒎'}, {'𘒄', '𗉋'}, {'𘒏', '𘒖'}, {'𗶯', '𘛣'}, {'𗶺', '𗶴'}, {'𘀢', '𗉠'}, {'𗡋', '𗆋'}, {'𘝯', '𗨚'}, {'𗑄', '𗓞'}, {'𘁝', '𘁱'}, {'𗈧', '𘝌'}, {'𗪞', '𘄳'}, {'𘝔', '𘝓'}, {'𘋉', '𘋊'}, {'𗪪', '𘄂'}, {'𘈢', '𘃰'}, {'𗀚', '𗒢'}, {'𘀘', '𗀫'}, {'𗀔', '𗀡'}, {'𗖵', '𗃱'}, {'𗿞', '𗿯'}, {'𘘝', '𘘚'}, {'𗲰', '𗲛'}, {'𗥖', '𗂹'}, {'𘄻', '𘄺'}, {'𗶎', '𗵼'}, {'𘇫', '𗉚'}, {'𘂭', '𗜶'}, {'𘏋', '𗷦'}, {'𗘎', '𗘋'}, {'𗘍', '𗘚'}, {'𗨔', '𗫅'}, {'𗷺', '𗷿'}, {'𗟱', '𗟷'}, {'𘚚', '𘚙'}, {'𗕚', '𗇰'}, {'𘕵', '𗚋'}, {'𗁮', '𗤷'}, {'𘐆', '𘎫'}, {'𘟔', '𘟕'}, {'𗧜', '𗥛'}, {'𗞰', '𘓟'}, {'𘆸', '𘌿'}, {'𘞸', '𗵱'}, {'𗙧', '𘄊'}, {'𗥄', '𗥇'}, {'𗘏', '𗘌'}, {'𗩨', '𗥷'}, {'𗟞', '𘟎'}, {'𗠡', '𗠒'}, {'𗤥', '𘌅'}, {'𘇄', '𗃇'}, {'𗽇', '𘍰'}, {'𗑓', '𗓆'}, {'𗚶', '𗛔'}, {'𗉞', '𗉖'}, {'𘆦', '𗉑'}, {'𗴿', '𗳞'}, {'𗄥', '𗄞'}, {'𗰣', '𘁷'}, {'𘛯', '𘛲'}, {'𗋮', '𗋔'}, {'𗗍', '𗖼'}, {'𘓙', '𘓚'}, {'𗋎', '𗊟'}, {'𗍋', '𗍑'}, {'𘜤', '𗟜'}, {'𘃋', '𘈞'}, {'𗐘', '𗐖'}, {'𗋂', '𘇓'}, {'𗥗', '𗥔'}, {'𗙃', '𘍑'}, {'𗙔', '𗇇'}, {'𘛻', '𗷠'}, {'𗘿', '𘏞'}, {'𗙕', '𘄇'}, {'𘞪', '𘞧'}, {'𘇁', '𘆬'}, {'𘞃', '𘞄'}, {'𘒿', '𘓀'}, {'𗇳', '𗎍'}, {'𗓐', '𗍥'}, {'𘝵', '𗨝'}, {'𗡣', '𗦢'}, {'𗖬', '𗎓'}, {'𗬚', '𘉍'}, {'𘋇', '𘊖'}, {'𗒁', '𘟠'}, {'𗤒', '𗩟'}, {'𘎁', '𘍸'}, {'𗏵', '𗏸'}, {'𗬣', '𗦵'}, {'𘈤', '𗳋'}, {'𘃍', '𗏑'}, {'𘙍', '𘙅'}, {'𘏆', '𘘲'}, {'𗖄', '𗼤'}, {'𘛈', '𗔂'}, {'𘒶', '𘒸'}, {'𗰖', '𗰠'}, {'𘁎', '𘅬'}, {'𗹽', '𗹰'}, {'𗄬', '𗸡'}, {'𗒫', '𗜟'}, {'𗹑', '𗹐'}, {'𘕕', '𘃒'}, {'𗉛', '𗰍'}, {'𘒲', '𘏺'}, {'𗢬', '𗪽'}, {'𘘟', '𘕢'}, {'𗯓', '𗯑'}, {'𘝚', '𘝛'}, {'𗭭', '𘎩'}, {'𘔊', '𘝷'}, {'𘋕', '𘑶'}, {'𗪾', '𘕒'}, {'𗆅', '𗅹'}, {'𗱸', '𘞉'}, {'𘉯', '𗡻'}, {'𗼄', '𗼛'}, {'𘖫', '𗫢'}, {'𗞒', '𗟉'}, {'𘒀', '𘒁'}, {'𗩻', '𘘦'}, {'𘆖', '𗣲'}, {'𗔫', '𘄏'}, {'𗭊', '𗨂'}, {'𘝻', '𘝼'}, {'𗆺', '𘙊'}, {'𗚗', '𗛻'}, {'𘕴', '𗂲'}, {'𘋗', '𘋚'}\n",
    "1. '𘀏', '𘀑'\n",
    "    1. 𘀏：族姓、音译字、老\n",
    "    2. 𘀑：【鵓】鳥名 譯音\n",
    "2. '𗚦', '𗚓'\n",
    "    1. 𗚦：鳩\n",
    "    2. 𗚓'【篤】、【督】族姓（族姓）\n",
    "3. '𗜹', '𗜦'\n",
    "    1. 𗜹：進、入\n",
    "    2. 𗜦：入、墮入、陷入\n",
    "4. '𗔟', '𘍿'\n",
    "    1. 𗔟：【紐】、【寧】族姓 譯音\n",
    "    2. 𘍿：鷹 名詞\n",
    "5. '𗩇', '𗿡'\n",
    "    1. 𗩇：【溫】、【文】 譯音，漢人姓、人名\n",
    "    2. 𗿡：【文】、【汶】地名 譯音\n",
    "6. '𗍎', '𗍘'\n",
    "    1. 𗍎：青玄色\n",
    "    2. 𗍘：蝴蝶 \n",
    "7. '𗿦', '𗿽'\n",
    "    1. 𗿦：雌、母、婦 \n",
    "    2. 𗿽：【麻】鳥名 譯音\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = max(nx.strongly_connected_components(G), key=len)\n",
    "print(largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心字集合的进一步精简\n",
    "\n",
    "kernel中如果有一个节点，入度为2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sccs = nx.strongly_connected_components(G)\n",
    "\n",
    "sccs_2 = [s for s in sccs if len(s) >= 2]\n",
    "print(len(sccs_2))\n",
    "\n",
    "print(sccs_2)\n",
    "\n",
    "scc_chars = 0\n",
    "for scc in sccs_2:\n",
    "    scc_chars += len(scc)\n",
    "    #print(scc)\n",
    "print(scc_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "论文<cite data-cite=\"1164965/M4LLKJ5H\"></cite>所提到的词典的核心有两种：1. kernel，跟我们前面通过不断删除出度为0的节点方法得到的是一样的；2. core：根据核心网络\n",
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = nx.DiGraph()\n",
    "with open('wenhai_gephi.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "    line = line.replace('\\n','')\n",
    "    edge = line.split(',')\n",
    "    #print(edge)\n",
    "    G1.add_node(edge[0])\n",
    "    G1.add_node(edge[1])\n",
    "    G1.add_edge(edge[1], edge[0])\n",
    "print(len(G1.nodes))\n",
    "\n",
    "sccs = nx.strongly_connected_components(G1)\n",
    "\n",
    "sccs_1 = [s for s in sccs if len(s) > 1]\n",
    "print(len(sccs_1))\n",
    "for scc in sccs:\n",
    "    #print(\"checking...\", scc)\n",
    "    #break\n",
    "    self_def = True\n",
    "    for n in scc:\n",
    "        prodecessors = list(G1.predecessors(n))\n",
    "        if len(prodecessors) == 0:\n",
    "            self_def = False\n",
    "            break\n",
    "        for p in prodecessors:\n",
    "            if p in scc:\n",
    "                continue\n",
    "            else:\n",
    "                self_def = False\n",
    "    if self_def:\n",
    "        print(\"Self_Defined\", scc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 《文海》定义层次\n",
    "1. Kernel定义距离\n",
    "一个字$w$的kernel定义距离：$w$可以由Kernel包含的节点所定义，如果$w$在Kernel集合中则$dist(w)=0$\n",
    "\n",
    "否则，如果有一条边从kernel集中指向$w$则表示$w$可以由kernel的词直接定义$dist(w)=1$\n",
    "\n",
    "    否则， $$dist(w) = 1 + max{dist(v): v is a prodecessor of u}$$\n",
    "    \n",
    "  这样，《文海》的层次就可以定义出来：\n",
    "  1. 第一层西夏字是属于kernel集的所有西夏字\n",
    "  2. 第二层西夏字是由kernel集中的西夏字直接定义的西夏字\n",
    "  3. 第三层西夏字是由kernel集中的西夏字经历两次推导定义的西夏字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.DiGraph()\n",
    "with open('wenhai_gephi.csv', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "    line = line.replace('\\n','')\n",
    "    edge = line.split(',')\n",
    "    #print(edge)\n",
    "    G0.add_node(edge[0])\n",
    "    G0.add_node(edge[1])\n",
    "    G0.add_edge(edge[1], edge[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前的《文海》词典中存在一些只解释其他词而却没有被解释的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for n in G0.nodes():\n",
    "    p = list(G0.predecessors(n))\n",
    "    if len(p) == 0:\n",
    "        i += 1\n",
    "        print(n)\n",
    "print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# rest中节点到kernel的定义路径\n",
    "def k_def(w, kernel):\n",
    "    if w in kernel.nodes():\n",
    "        return 0\n",
    "    else:\n",
    "        t = list(G0.predecessors(w))\n",
    "        if len(t) == 2: # 有两个定义字符，按照《文海》定义应该都有两个父节点\n",
    "            t1 = k_def(t[0], kernel) + 1\n",
    "            t2 = k_def(t[1], kernel) + 1\n",
    "            return max(t1, t2)\n",
    "        elif len(t) == 1: # 有一个定义字符\n",
    "            print(f\"only one predecessor: {t}\")\n",
    "        else: # 没有定义字符\n",
    "            return -100\n",
    "        \n",
    "print(f\"kernel size:{len(G.nodes())}\")\n",
    "\n",
    "\n",
    "hierarchies = {}          \n",
    "for c in rest:\n",
    "    #print(c)\n",
    "    t = k_def(c, G)\n",
    "    hierarchies[c] = t\n",
    "    #print(t)\n",
    "    #print(\"--------\")\n",
    "print(hierarchies)\n",
    "for i in range(1, 7):\n",
    "    h = [(k,hierarchies[k]) for k in hierarchies.keys() if hierarchies[k] == i]\n",
    "    print(f'{i}层字数: {len(h)}')\n",
    "\n",
    "youli = [[(k,hierarchies[k]) for k in hierarchies.keys() if hierarchies[k] < 0]]\n",
    "print(len(youli[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size = len(G.nodes)\n",
    "print(f\"Kernel包含:{k_size}\")\n",
    "\n",
    "# 由kernel导出的字\n",
    "k_induce = 1141+346+70+20+4\n",
    "print(f\"由kernel导出的字：{k_induce}\")\n",
    "d_size = len(G0.nodes)\n",
    "print(f\"图中所有字:{d_size}\")\n",
    "\n",
    "print(f\"kernel及其可定义的字占所有字的比例：{(k_size+k_induce)/d_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义kernel距离\n",
    "def k_dis(w, kernel):\n",
    "    if w in kernel.nodes():\n",
    "        return 0\n",
    "    else:\n",
    "        t = list(G0.predecessors(w))\n",
    "        if len(t) == 2:\n",
    "            print(t[0])\n",
    "            print(t[1])\n",
    "            return(max(k_dis(t[0], kernel) + 1, k_dis(t[1], kernel) + 1))\n",
    "        else:\n",
    "            return 1000\n",
    "        \n",
    "        #return (max(k_dis(t[0], kernel)+1, k_dis(t[1], kernel) + 1))\n",
    "        #return(k_dis(t[0], kernel)+1)\n",
    "\n",
    "for c in rest:\n",
    "    print(c)\n",
    "    t = k_dis(c, G)\n",
    "    print(t)\n",
    "    print(\"--------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "nodes = G.out_degree()\n",
    "nodes = dict(nodes)\n",
    "nodes = sorted(nodes.items(), key=lambda d: d[1]) \n",
    "print(nodes)"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "1164965/M4LLKJ5H": {
     "DOI": "10.1111/tops.12211",
     "URL": "https://onlinelibrary.wiley.com/doi/full/10.1111/tops.12211",
     "abstract": "Abstract How many words?and which ones?are sufficient to define all other words? When dictionaries are analyzed as directed graphs with links from defining words to defined words, they reveal a latent structure. Recursively removing all words that are reachable by definition but that do not define any further words reduces the dictionary to a Kernel of about 10% of its size. This is still not the smallest number of words that can define all the rest. About 75% of the Kernel turns out to be its Core, a ?Strongly Connected Subset? of words with a definitional path to and from any pair of its words and no word's definition depending on a word outside the set. But the Core cannot define all the rest of the dictionary. The 25% of the Kernel surrounding the Core consists of small strongly connected subsets of words: the Satellites. The size of the smallest set of words that can define all the rest?the graph's ?minimum feedback vertex set? or MinSet?is about 1% of the dictionary, about 15% of the Kernel, and part-Core/part-Satellite. But every dictionary has a huge number of MinSets. The Core words are learned earlier, more frequent, and less concrete than the Satellites, which are in turn learned earlier, more frequent, but more concrete than the rest of the Dictionary. In principle, only one MinSet's words would need to be grounded through the sensorimotor capacity to recognize and categorize their referents. In a dual-code sensorimotor/symbolic model of the mental lexicon, the symbolic code could do all the rest through recombinatory definition.",
     "accessed": {
      "day": 22,
      "month": 4,
      "year": 2020
     },
     "author": [
      {
       "family": "Vincent-Lamarre",
       "given": "Philippe"
      },
      {
       "family": "Massé",
       "given": "Alexandre Blondin"
      },
      {
       "family": "Lopes",
       "given": "Marcos"
      },
      {
       "family": "Lord",
       "given": "Mélanie"
      },
      {
       "family": "Marcotte",
       "given": "Odile"
      },
      {
       "family": "Harnad",
       "given": "Stevan"
      }
     ],
     "container-title": "Topics in Cognitive Science",
     "container-title-short": "Topics in Cognitive Science",
     "id": "1164965/M4LLKJ5H",
     "issue": "3",
     "issued": {
      "day": 1,
      "month": 7,
      "year": 2016
     },
     "journalAbbreviation": "Topics in Cognitive Science",
     "note": "Publisher: John Wiley & Sons, Ltd",
     "page": "625-659",
     "page-first": "625",
     "title": "The Latent Structure of Dictionaries",
     "type": "article-journal",
     "volume": "8"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
